/*
 * Copyright (c) 2009-2016, SanDisk Corporation. All rights reserved.
 * No use, or distribution, of this source code is permitted in any form or
 * means without a valid, written license agreement with SanDisk Corp.  Please
 * refer to the included End User License Agreement (EULA), "License" or "License.txt" file
 * for terms and conditions regarding the use and redistribution of this software.
 */

/*
 * File:   fcnl_framework_replica_node_test.c
 * Author: Songhe
 *
 * Created on Jun 15, 2009
 *
 * (c) Copyright 2009, Schooner Information Technology, Inc.
 * http://www.schoonerinfotech.com/
 *
 * $Id: fcnl_framework_recover_test.c 7929 2009-06-11 04:17:27Z drew $
 */

/* Test switch-over, recovery, switch-back */

#include "fth/fthOpt.h"
#include "platform/stdio.h"
#include "test_framework.h"

#undef MILLION
#define MILLION 1000000

#define RT_USE_COMMON 1
#include "test_common.h"

/*
 * We use a sub-category under test because test implies a huge number
 * of log messages out of simulated networking, flash, etc.
 */
PLAT_LOG_SUBCAT_LOCAL(LOG_CAT, PLAT_LOG_CAT_SDF_PROT_REPLICATION,
                      "test/case");

#define PLAT_OPTS_NAME(name) name ## _sync_test
#include "platform/opts.h"
#include "misc/misc.h"

#define PLAT_OPTS_ITEMS_sync_test() \
    PLAT_OPTS_COMMON_TEST(common_config)

#define SLEEP_US 1000000

struct plat_opts_config_sync_test {
    struct rt_common_test_config common_config;
};

/**
 * @brief synchronized create_shard/write/read/delete/delete_shard operations
 */
void
user_operations_sync(uint64_t args) {
    struct replication_test_framework *test_framework =
            (struct replication_test_framework *)args;

    SDF_boolean_t op_ret;
    struct SDF_shard_meta *shard_meta = NULL;
    SDF_replication_props_t *replication_props = NULL;
    int failed;
    SDF_shardid_t shard_id;

    shard_id = __sync_add_and_fetch(&test_framework->max_shard_id, 1);

    failed = !plat_calloc_struct(&meta);
    plat_assert(!failed);
    replication_test_meta_init(meta);


    /* Assure test_framework is started?! */
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "start test_framework");
    rtfw_start(test_framework);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "test_framework started\n");

    /* Start all nodes */
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "start nodes");
    rtfw_start_all_nodes(test_framework);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "nodes started");

    failed = !plat_calloc_struct(&replication_props);
    plat_assert(!failed);
    rtfw_set_default_replication_props(&test_framework->config,
                                       replication_props);
    shard_meta = rtfw_init_shard_meta(&test_framework->config, 1 /* first */,
                                      shard_id
                                      /* shard_id, in real system generated by generate_shard_ids() */,
                                      replication_props);

    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "create on node 1");
    op_ret = rtfw_create_shard_sync(test_framework, 1, shard_meta);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "create on node 1 complete");
    plat_assert(op_ret == SDF_SUCCESS);

    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "crash node 2");
    op_ret = rtfw_crash_node_sync(test_framework, 2);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "crash node 2 complete");
    plat_assert(op_ret == SDF_SUCCESS);

    /* Sleep through the lease until switchover happens */
    rtfw_sleep_usec(test_framework,
                    test_framework->config.replicator_config.lease_usecs * 2);


    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "start node 2");
    op_ret = rtfw_start_node(test_framework, 2);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "start node 2 complete");
    plat_assert(op_ret == SDF_SUCCESS);

    /* Wait for recovery.  Delay is arbitrary and long */
    rtfw_sleep_usec(test_framework,
                    test_framework->config.replicator_config.lease_usecs);

    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "shutdown");
    rtfw_shutdown_sync(test_framework);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "shutdown complete");

    plat_free(meta);
    plat_free(replication_props);
    plat_free(shard_meta);

    /* Terminate scheduler if idle_thread exit */
    while (test_framework->timer_dispatcher) {
        fthYield(-1);
    }
    plat_free(test_framework);

    fthKill(1);
}

int main(int argc, char **argv) {
    SDF_status_t status;
    struct replication_test_framework *test_framework = NULL;

    struct plat_opts_config_sync_test opts_config;
    memset(&opts_config, 0, sizeof (opts_config));

    rt_common_test_config_init(&opts_config.common_config);
    /* Two plus the super node */
    opts_config.common_config.test_config.nnode = 4;
    opts_config.common_config.test_config.num_replicas = 3;
    opts_config.common_config.test_config.replication_type =
        SDF_REPLICATION_META_SUPER_NODE;
    opts_config.common_config.test_config.replicator_config.lease_usecs =
        100 * MILLION;


    int opts_status = plat_opts_parse_sync_test(&opts_config, argc, argv);
    if (opts_status) {
        return (1);
    }

    status = rt_sm_init(&opts_config.common_config.shmem_config);
    if (status) {
        return (1);
    }

    /* start fthread library */
    fthInit();

    test_framework =
        replication_test_framework_alloc(&opts_config.common_config.test_config);
    if (test_framework) {
        plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "test_framework %p allocated\n",
                     test_framework);
    }
    XResume(fthSpawn(&user_operations_sync, 40960), (uint64_t)test_framework);
    fthSchedulerPthread(0);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "JOIN");

    rt_sm_detach();

    rt_common_test_config_destroy(&opts_config.common_config);

    return (0);
}

#include "platform/opts_c.h"
