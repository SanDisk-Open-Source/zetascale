//----------------------------------------------------------------------------
// ZetaScale
// Copyright (c) 2016, SanDisk Corp. and/or all its affiliates.
//
// This program is free software; you can redistribute it and/or modify it under
// the terms of the GNU Lesser General Public License version 2.1 as published by the Free
// Software Foundation;
//
// This program is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
// FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License v2.1 for more details.
//
// A copy of the GNU Lesser General Public License v2.1 is provided with this package and
// can also be found at: http://opensource.org/licenses/LGPL-2.1
// You should have received a copy of the GNU Lesser General Public License along with
// this program; if not, write to the Free Software Foundation, Inc., 59 Temple
// Place, Suite 330, Boston, MA 02111-1307 USA.
//----------------------------------------------------------------------------

/*
 * File: fcnl_sn_multi_shard_test2.c
 * Author: Zhenwei Lu
 *
 * Scenario:
 * 2 nodes, 0, 1
 * shard 101 (1, 0) 1 is home node
 * shard 100 (0, 1) 0 is home node
 * crash node 1 and restart, so both shard 0 and shard 1 should be recovered
 *
 * Created on Jun 19, 2009, 12:04 AM
 *
 * Copyright Schooner Information Technology, Inc.
 * http://www.schoonerinfotech.com/
 *
 * $Id$
 */

/**
 * To reproduce a problem Songhe found in system testing
 */

#include "fth/fthOpt.h"
#include "platform/stdio.h"
#include "test_framework.h"

#define RT_USE_COMMON 1
#include "test_common.h"

/*
 * We use a sub-category under test because test implies a huge number
 * of log messages out of simulated networking, flash, etc.
 */
PLAT_LOG_SUBCAT_LOCAL(LOG_CAT, PLAT_LOG_CAT_SDF_PROT_REPLICATION,
                      "test/case");


#define PLAT_OPTS_NAME(name) name ## _sync_test
#include "platform/opts.h"
#include "misc/misc.h"

#define PLAT_OPTS_ITEMS_sync_test() \
    PLAT_OPTS_COMMON_TEST(common_config)

#define SLEEP_US 1000000

struct plat_opts_config_sync_test {
    struct rt_common_test_config common_config;
};

#define NUM_REPLICAS 2

void
user_operations_ms_test(uint64_t args) {
    struct replication_test_framework *test_framework =
        (struct replication_test_framework *)args;
    SDF_shardid_t shard_id[2] = {100, 101};
    struct SDF_shard_meta *shard_meta[2];
    /* configuration infomation about shard */
    SDF_replication_props_t *replication_props = NULL;
    SDF_status_t op_ret = SDF_SUCCESS;
    vnode_t node[2] = {0, 1};
    int failed, i;

    char key1[] = "key1";
    char *key;
    size_t key_len;
    char *data;
    int data_generation = 0;

    failed = !plat_calloc_struct(&meta);
    plat_assert(!failed);
    replication_test_meta_init(meta);

    /* Assure test_framework is started?! */
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "start test_framework");
    rtfw_start(test_framework);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "test_framework started\n");

    /* Start all nodes */
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "start nodes");
    rtfw_start_all_nodes(test_framework);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "nodes started");


    /* configures test framework accommodate to RT_TYPE_META_STORAGE */
    failed = !(plat_calloc_struct(&replication_props));
    plat_assert(!failed);

    /* initialize replciation properties and create shards */
    rtfw_set_default_replication_props(&test_framework->config,
                                       replication_props);
    for (i = 0; i < NUM_REPLICAS; i++) {
        shard_meta[i] = rtfw_init_shard_meta(&test_framework->config, node[i] /* first */,
                                             shard_id[i]
                                             /* shard_id, in real system generated by generate_shard_ids() */,
                                             replication_props);
        plat_assert(shard_meta[i]);

        plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "create on node %d", i);
        op_ret = rtfw_create_shard_sync(test_framework, node[i], shard_meta[i]);
        plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "create on node %d complete", i);
        /* seems both meta data shard of shard_id[0] and shard_id[1] mapping to shard 0 */
        /* plat_assert(op_ret == SDF_SUCCESS); */
    }

    /* write to node 1 an object */
    plat_asprintf(&data, "data_%s_%d_%s_%d", "node", i, key1, data_generation);
    key = key1;
    key_len = strlen(key) + 1;
    plat_log_msg(LOG_ID, LOG_CAT, LOG_TRACE,
                 "write on node %d key:%s, key_len:%u, data:%s, data_len:%u",
                 1, key, (int)(strlen(key)), data, (int)(strlen(data)));
    op_ret = rtfw_write_sync(test_framework,
                             shard_id[1] /* shard */, 1 /* node */,
                             meta /* test_meta */, key, key_len, data,
                             strlen(data)+1);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "write on node %d complete", 1);
    plat_assert(op_ret == SDF_SUCCESS);

    /* crash node1 */
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "crash node 1");
    op_ret = rtfw_crash_node_sync(test_framework, 1);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "crash node 1 complete");
    plat_assert(op_ret == SDF_SUCCESS);
    /* Sleep through the lease until switchover happens */
    rtfw_sleep_usec(test_framework,
                    test_framework->config.replicator_config.lease_usecs * 2);
#if 0
    /* read from node0 to verify home node switch */
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "read on node 0 shard %d", (int)shard_id[1]);
    key = key2;
    key_len = strlen(key) + 1;
    op_ret = rtfw_read_sync(test_framework, shard_id[1], 0, key, key_len,
                            &data_out, &data_len_out, &free_cb);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "read on node 2 shard %d complete", (int)shard_id[1]);
    plat_assert(op_ret == SDF_SUCCESS);
    plat_assert(strcmp(data_out, data) == 0);
    plat_closure_apply(replication_test_framework_read_data_free_cb, &free_cb,
                       data_out, data_len_out);
#endif

    /* restart node1 to recovery both shard 1 and shard 2 */
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "start node 1");
    op_ret = rtfw_start_node(test_framework, 1);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "start node 1 complete");
    plat_assert(op_ret == SDF_SUCCESS);

    /* Wait for recovery.  Delay is arbitrary and long */
    rtfw_sleep_usec(test_framework,
                    test_framework->config.replicator_config.lease_usecs);
#if 0
    /* read from node1  */
#endif

    /* Shutdown test framework */
    plat_log_msg(LOG_ID, LOG_CAT, LOG_TRACE,
                 "\n************************************************************\n"
                 "                  Test framework shutdown                       "
                 "\n************************************************************");
    rtfw_shutdown_sync(test_framework);

    plat_free(data);
    plat_free(meta);
    plat_free(replication_props);
    plat_free(shard_meta[0]);
    plat_free(shard_meta[1]);

    /* Terminate scheduler if idle_thread exit */
    while (test_framework->timer_dispatcher) {
        fthYield(-1);
    }
    plat_free(test_framework);

    /* Terminate scheduler */
    fthKill(1);
}

int main(int argc, char **argv) {
    SDF_status_t status;
    struct replication_test_framework *test_framework = NULL;

    struct plat_opts_config_sync_test opts_config;
    memset(&opts_config, 0, sizeof (opts_config));

    rt_common_test_config_init(&opts_config.common_config);
    opts_config.common_config.test_config.nnode = NUM_REPLICAS;
    opts_config.common_config.test_config.replication_type =
        SDF_REPLICATION_META_SUPER_NODE;
    opts_config.common_config.test_config.replicator_config.lease_usecs =
        100 * MILLION;


    int opts_status = plat_opts_parse_sync_test(&opts_config, argc, argv);
    if (opts_status) {
        return (1);
    }

    status = rt_sm_init(&opts_config.common_config.shmem_config);
    if (status) {
        return (1);
    }

    /* start fthread library */
    fthInit();

    test_framework =
        replication_test_framework_alloc(&opts_config.common_config.test_config);
    if (test_framework) {
        plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "test_framework %p allocated\n",
                     test_framework);
    }
    XResume(fthSpawn(&user_operations_ms_test, 40960), (uint64_t)test_framework);
    fthSchedulerPthread(0);
    plat_log_msg(LOG_ID, LOG_CAT, LOG_DBG, "JOIN");

    rt_sm_detach();

    rt_common_test_config_destroy(&opts_config.common_config);

    return (0);
}
#include "platform/opts_c.h"
